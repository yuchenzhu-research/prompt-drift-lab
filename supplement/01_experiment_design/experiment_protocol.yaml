# experiment_protocol.yaml
# Scope: experimental setup only
# This file MUST NOT define or interpret any evaluation or scoring rules.

stages:
  development:
    questions: [Q1, Q2]
    purpose: prompt iteration and sanity checking
    reported: false
    artifacts:
      - prompt_dev_log.md

  evaluation:
    questions: [Q3, Q4]
    purpose: output generation for downstream evaluation
    reported: true

experiment:
  bundle_size: 16
  questions: [Q3, Q4]
  variants:
    - baseline
    - long
    - weak
    - conflict
  trigger_types:
    - implicit
    - explicit
  output_files:
    naming_template: q{question}_{variant}_{trigger}.pdf

output_contract:
  description: >
    This contract specifies the expected structural layout of model outputs.
    It does not define task semantics, quality criteria, or evaluation logic.
    Any deviation from this contract is handled exclusively by the
    evaluation protocol.
  sections:
    - fact snapshot
    - ChatGPT web search instructions
    - Gemini deep research instructions

evaluation_reference:
  authority: supplement/03_evaluation_rules
  note: >
    All scoring scales, validity criteria, failure definitions, and
    judgment procedures are defined exclusively in the evaluation
    rules directory and are not duplicated here.