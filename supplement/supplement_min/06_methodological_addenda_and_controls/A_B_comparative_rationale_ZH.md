# A/B 对照依据：引入 A vs. B 以及以 B 为 Anchor 的论证

本文旨在回答两个核心问题：

- **为什么需要显式引入 A/B 对照**；
- **为什么后续的 long、weak、conflict 等微扰实验统一以 Prompt B 作为基准（anchor）**。

全文仅基于本项目**已经完成并落盘的实验设计与结果**展开，不引入任何未实施的方法或假设。

---

## 1. A 与 B 的最小差分定义

Prompt A 与 Prompt B 之间的差分，**仅围绕“结构化程度与约束强度”这一核心轴展开**。

- **Prompt A**：以自然语言描述为主，结构边界较弱，对输出形式的约束相对宽松；
- **Prompt B**：引入显式字段、顺序要求与禁止项等硬约束，对输出结构提出可执行要求。

在设计 A/B 对照时，遵循以下控制原则：

- 不引入新的任务内容；
- 不改变题集、模型参数或 judge 评测协议；
- 差异主要体现在输出结构的**可执行性**与**可验证性**上。

对应的审计入口位于：`02_prompt_variants/PROMPT_MANIFEST.md`。

---

## 2. 引入 A/B 对照的必要性

在缺乏 A/B 对照的情况下，prompt drift 的参照系往往不清晰，具体表现为：

- 当出现格式崩坏时，难以区分是模型能力问题，还是 prompt 结构表达不足；
- 后续微扰（如 weak、long、conflict）的退化程度缺乏明确的基线；
- invalid 比例上升时，无法判断是由微扰引入，还是基线本身就不可评测。

A/B 对照为上述问题提供了一个最基本的坐标系：

- **Prompt A** 代表约束较弱、更接近自然交互的场景；
- **Prompt B** 代表可评测、可对齐的结构化锚点。

---

## 3. 以 Prompt B 作为 Anchor 的选择依据

### 3.1 可评测性

当输出结构稳定性不足时，样本更容易被归入 invalid 集合，统计结果将被格式噪声主导。Prompt B 的约束设计旨在提高**可评测样本比例**，使评测关注点更多集中于指令遵循与语义偏离本身。

### 3.2 微扰空间的可解释性

以 Prompt B 作为 anchor，后续微扰可以被理解为**在同一约束体系下的定向扰动**：

- **weak**：系统性降低结构与硬约束强度；
- **long**：在保持约束不变的前提下增加上下文负担并引入干扰；
- **conflict**：引入指令张力，用于检验模型的隐式优先级处理。

### 3.3 跨模型可比性

在输出结构更稳定的前提下，不同 judge 模型更容易对齐评分对象，从而降低因格式噪声引入的评测偏差，提升跨模型比较的可信度。

---

## 4. 证据链的组织方式

本项目中，A/B 对照相关证据按如下顺序组织：

1. 从 `04_results/summary.csv` 中定位 A 与 B 在 hard compliance、invalid rate 等指标上的差异；
2. 抽样回看对应的 PDF 输出，确认差异主要来自结构遵循，而非偶然的内容波动；
3. 检查对应的 judge JSON，核对 invalid 判定与评分理由是否符合评测协议；
4. 在此基础上，再分析基于 Prompt B 的 weak、long、conflict 微扰，验证相对退化方向是否与失败模式映射一致。

---

## 5. 局限与风险控制

- A/B 之间仍可能存在长度或语气层面的次要差分，需要通过进一步控制实验或消融分析加以限制；
- 不同模型对结构化指令的可执行性存在差异，最优 anchor 的选择可能随模型变化；
- 自动 judge 可能存在结构偏好，可通过跨模型互评、自评、人工抽检或 judge 互换等方式降低偏置。

