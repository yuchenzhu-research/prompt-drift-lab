## 提示词 A/B 对比（Prompt Drift 的核心自变量）

本项目的“提示词漂移（prompt drift）”并不是指模型参数变化，而是指**在任务不变的前提下**，仅对提示词的格式/措辞/约束表达做轻微调整时，模型输出在**遵循率、结构稳定性、语义一致性**等方面出现系统性变化。

为让读者复现时不混淆术语，本仓库把提示词相关变量拆成两层（与 `01_实验设计/README.md`、`02_提示词版本/README.md` 对齐）：

- **Prompt Family（提示词家族/模板家族）**：A vs B（两套“三段式模板”）
- **Prompt Variant（提示词微扰/扰动版本）**：baseline / long / weak / conflict …（在选定某个 Family 后做可控微扰；主实验通常固定在 B）

> **本报告的定量结论以 Prompt B（协议版）产物为准。**  
> Prompt A（探索版）仅用于质性对照与机制线索，不进入任何分数汇总/均值/对比图表（除非与 B 完全同覆盖、同对齐并在统计口径中明确声明）。

---

### 1) A 与 B 的定位（为什么会有两版）

- **提示词 A（探索版）**：更偏“自然语言说明 + 期望格式”，约束相对松，便于早期快速跑通流程、收集失败样本、观察模型常见偏离点。  
- **提示词 B（协议版）**：在保持三段式结构不变的前提下，把关键约束写得更“可执行/可复核”，通过**结构锚定、负向约束、机制要求与信息密度控制**，提升输出稳定性与跨样本可对齐性，因此被用作主实验统一模板。

> 提示词文件与对比说明位于 `02_提示词版本/`（读者复现时以仓库中的实际文件为准）。

---

### 2) 关键差异（对可复现性的影响）

| 维度 | A（探索版） | B（协议版） | 对结果的直接影响 |
|---|---|---|---|
| 目标 | 先跑通/先观察现象 | 产出稳定、可对齐的主实验产物 | B 更适合作为主实验统一模板 |
| 结构锚定 | 结构边界相对松 | 标题/锚点更明确，强制三段式边界 | B 降低“段落合并/结构漂移” |
| 负向约束 | 较少或较弱 | 明确禁止常见跑偏（泛泛而谈/提前长篇分析/跳过任务等） | B 降低“表面合规但关键约束被忽略” |
| 机制要求 | 偏内容总结 | 强制提出机制假说/分歧点/最小验证实验 | B 更利于后续归因与写作（机制解释可复核） |
| 信息密度/长度 | 更自由 | 对粒度、边界与风格更可控 | B 降低“越写越散/变成文章”导致的漂移 |
| 统计口径 | 常覆盖不完整 | 用于全覆盖的主实验口径 | 避免把 A 的缺口混入统计造成假差异 |

---

### 3) 本报告中如何使用 A/B（避免读者误解）

- **主结论与分数汇总**：以 **Prompt B** 产物为准（主实验统一模板 + 可对齐统计口径）。  
- **A/B 对比的用途**：用于展示“轻微措辞/约束变化会导致遵循率下降、格式崩坏或语义漂移”的现象，属于**质性对照**与**机制解释线索**。  
- **A 不进入统计**：若 A 的覆盖范围与 B 不完全对齐（例如仅在早期跑过部分题目/模型/变体组合），则不将 A 的分数纳入任何平均值与对比图表，以免形成假差异。

---

### 4) A/B 与评测协议（Rubric/Judge Prompt）的关系

需要特别区分两件事：

1. **A/B 是“生成侧提示词模板”**：决定被测模型在任务执行时如何组织三段式输出。  
2. **评测协议是“评测侧规则”**：位于 `03_评测规则/`，决定 judge 如何判分、如何标注 invalid、以及（若采用结构化输出）如何落盘为可解析格式。

因此，“B 更稳定”指的是 **被测模型输出更容易对齐与复核**；并不等价于“评测输出一定是 JSON”。（评测侧是否 JSON 取决于你在评测规则中的设计。）

---

## 评测失效（Invalid）与失败模式（Failure Modes）

本项目在 `02_跨模型评测结果/无效评测/` 中对无法作为定量依据的评测结果进行了隔离，并为每条无效评测标注了机器可读的失效标签（`flags`）。本节不将其纳入统计结论，而是将其作为**失败模式样本库**，用于界定评测边界、解释异常现象来源，并约束后续协议/提示词迭代方向。

### 1) 无效评测的使用原则

- 无效评测 **不进入任何分数汇总、平均值、对比图表**。
- 无效评测 **只用于**：
  - 归纳失败模式（failure modes）；
  - 解释“为什么某些组合下结果不可比/不可复核”；
  - 给出协议与提示词的最小改进建议（只改可执行性，不改实验结论）。

### 2) 失败模式标签体系（与目录对齐）

| 标签（flags） | 失败模式定义 | 最常见触发点 | 对研究结论的影响 | 处理策略（工程化） |
|---|---|---|---|---|
| `PROTOCOL_VIOLATION` | 评测未按协议执行（维度/标尺/输出约束被更改） | judge“自作主张”换标准、加维度、输出形态不符 | 破坏跨模型可比性，可能产生虚假差异 | 固化协议 + 强制结构校验（字段/尺度/阈值），不合格直接归 invalid |
| `UNPARSABLE_OUTPUT` | 输出不可解析（结构崩坏/字段缺失/混入大段自然语言；若采用 JSON 则包括 JSON 不闭合） | 输出混合格式、关键字段缺失、结构不完整 | 无法进入统计；会造成样本缺口 | 增加结构约束 + 解析校验（如 JSON/字段完整性）；必要时分离 evidence 与 notes |
| `INCOMPLETE_COVERAGE` | 评测覆盖不完整（样本缺失或无法对齐） | 漏模型/漏题、bundle 对应关系不清、A/B 覆盖不一致 | A/B 对照与跨模型对齐失效 | 先锁定样本清单（manifest），评测前后做 coverage diff |
| `JUDGE_REFUSAL_OR_EVASION` | 拒评/回避导致无有效评分 | 安全声明、拒绝打分、泛泛而谈不落字段 | 产生系统性缺评；不同 judge 之间不可比 | 增加“拒评也要输出 FAIL+flags 的结构化结果”的规则；仍不合规则归 invalid |
| `INTERNAL_INCONSISTENCY` | 内部不一致（分项与总分/结论矛盾） | overall 与分项和不一致、verdict 与阈值冲突 | 能解析但不可置信；会污染统计 | 增加一致性校验（sum check / threshold check），失败即 invalid |
| `CONTEXT_MISALIGNMENT` | 上下文错位（评错对象/题目/版本/变体） | 混淆 Q3/Q4、A/B、baseline/long 等 | 产生假漂移、假差异 | meta 强约束 + 输入格式固定（显式携带 question_id / prompt_family / variant / target_model） |
| `SELF_JUDGING_BIAS` | 自评偏置（方法学限制） | 模型对自身输出评测 | 不宜作为主结论 | 仅用于 sanity check，单独分桶 |

### 3) 将无效评测映射为“漂移研究”的可观察症状

无效评测并不只意味着评测失败，它往往对应两类可观察症状：

1. **评测侧失效（judge-side failure）**
   - 典型标签：`PROTOCOL_VIOLATION`、`UNPARSABLE_OUTPUT`、`JUDGE_REFUSAL_OR_EVASION`、`INTERNAL_INCONSISTENCY`
   - 解释含义：评测规则/评测提示词对 judge 的“可执行性”不足，导致评测链路不稳定。

2. **对齐侧错配（alignment-side mismatch）**
   - 典型标签：`CONTEXT_MISALIGNMENT`、`INCOMPLETE_COVERAGE`
   - 解释含义：样本对齐与元信息约束不足，造成“比较对象不一致”，从而产生假漂移或不可比。

### 4) 本轮无效评测的记录方式（读者可复核）

- 主方法（跨模型互评）：`02_跨模型评测结果/无效评测/主方法_跨模型互评/`
- 辅助方法（模型自评）：`02_跨模型评测结果/无效评测/辅助方法_模型自评/`

每个无效评测文件顶层均包含：
- `meta`：`judge_model / target_model / method / judge_prompt_id`
- `flags`：上述标签之一（或少量组合）

这使得读者可在不依赖额外脚本的情况下，直接检查“失效类型分布”与“失效是否集中在特定 judge/target 组合”。

### 5) 最小化改进建议（不改变既有结论）

本节只给出不会引入结果返工的“最小工程修复”，用于降低无效评测率：

- **结构校验前置**：评测输出落盘前做结构检查；若采用 JSON 则进行 JSON 解析 + 字段完整性 + 一致性检查（sum/阈值）。
- **样本清单锁定**：评测前生成 manifest（question × variant × model），评测后做 coverage diff。
- **meta 强约束**：将 `question_id / prompt_family / prompt_variant / output_id` 作为 judge 输入的固定头部，减少错配。
- **自评单独分桶**：自评结果仅用于 sanity check，不与跨模型互评混合统计。

> 若后续迭代需要扩大测试集或引入更多模型，本节标签体系仍可直接复用，以保证跨版本可比。

